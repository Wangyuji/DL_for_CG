{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d4156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c666c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "File2 exists: True\n",
      "Load data from tictac_final\n",
      "(958, 9)\n",
      "(958, 1)\n",
      "(6551, 9)\n",
      "(6551, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'D:\\\\UFL\\\\cap5404\\\\Part1\\\\tictactoedatasets\\\\tictac_final.txt'\n",
    "print('File exists:', os.path.exists(file_path))\n",
    "file_path2 = 'D:\\\\UFL\\\\cap5404\\\\Part1\\\\tictactoedatasets\\\\tictac_multi.txt'\n",
    "print('File2 exists:', os.path.exists(file_path2))\n",
    "print(\"Load data from tictac_final\")\n",
    "np.arr = np.loadtxt(file_path)\n",
    "np.arr2 = np.loadtxt(file_path2)\n",
    "\n",
    "X = np.arr[:, : 9 ]\n",
    "Y = np.arr[:, 9 : ]\n",
    "\n",
    "X2 = np.arr2[:, : 9 ]\n",
    "Y2 = np.arr2[:, 9 : ]\n",
    "    \n",
    "#Y = Y.reshape((958,9))\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print(X2.shape)\n",
    "print(Y2.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1121f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_final file:\n",
      "(191, 9) (191, 1)\n",
      "(767, 9) (767, 1)\n",
      "====================\n",
      "dataset_multi file:\n",
      "(1310, 9) (1310, 9)\n",
      "(5241, 9) (5241, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset_final file:\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.8)\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)\n",
    "print(\"=\"*20)\n",
    "\n",
    "print(\"dataset_multi file:\")\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size = 0.8)\n",
    "print (x_train2.shape, y_train2.shape)\n",
    "print (x_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf38b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_MLP():\n",
    "    param_setting =[{\n",
    "        'hidden_layer_sizes': [(150,100,50,10)],\n",
    "        'activation':['relu', 'sigmoid'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant']\n",
    "    }]\n",
    "    \n",
    "    kfd = KFold(n_splits = 20, shuffle=True, random_state = 10)\n",
    "    \n",
    "    iter_clf = MLPClassifier(max_iter = 1000)\n",
    "    #class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, \n",
    "    #scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, \n",
    "    #return_train_score=False)[source]\n",
    "    clf = GridSearchCV(iter_clf, param_setting, n_jobs =-1, cv=kfd, scoring=\"accuracy\")\n",
    "    \n",
    "    iter_reg = MLPRegressor(random_state=20, max_iter=1000)\n",
    "    \n",
    "    reg = GridSearchCV(iter_reg, param_setting, cv=kfd, n_jobs=-1)\n",
    "    \n",
    "    return clf, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fcc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_classifier(x_train, y_train, x_test, y_test):\n",
    "    clf, reg = _init_MLP()\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    best_score = clf.best_score_\n",
    "    best_params = clf.best_params_\n",
    "    best_esti = clf.best_estimator_\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    print(\"The best socre is: \")\n",
    "    print(best_score)\n",
    "    print(\"The best params is: \")\n",
    "    print(best_params)\n",
    "    #print(\"The best estimator is: \")\n",
    "    #print(best_esti)\n",
    "    #print(\"The best prediction for y is: \")\n",
    "    #print(y_pred)\n",
    "    #print(y_test)\n",
    "    \n",
    "    #nomalize default is true here\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    test_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    print('Test accuracy with normalize flase: \\n', test_acc)  \n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = cm/cm.astype(np.float).sum(axis = 1)\n",
    "    print(\"Confusion Matrix is: \")\n",
    "    print(cm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f486dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.925      0.95055556        nan        nan]\n",
      "  warnings.warn(\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best socre is: \n",
      "0.9505555555555556\n",
      "The best params is: \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (150, 100, 50, 10), 'learning_rate': 'constant'}\n",
      "Test accuracy: 0.9569752281616688\n",
      "Test accuracy with normalize flase: \n",
      " 734\n",
      "Confusion Matrix is: \n",
      "[[0.92592593 0.04024145]\n",
      " [0.04814815 0.97384306]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14044\\AppData\\Local\\Temp\\ipykernel_21596\\819140789.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cm = cm/cm.astype(np.float).sum(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "MLP_classifier(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268e0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def MLP_regressor(x_train, y_train, x_test, y_test):\n",
    "    clf, reg = _init_MLP()\n",
    "    reg.fit(x_train, y_train)\n",
    "     \n",
    "    best_score = reg.best_score_\n",
    "    best_params = reg.best_params_\n",
    "    best_esti = reg.best_estimator_\n",
    "    y_pred1 = reg.predict(x_test)\n",
    "    \n",
    "    print(\"The best socre is: \")\n",
    "    print(best_score)\n",
    "    print(\"The best params is: \")\n",
    "    print(best_params)\n",
    "    \n",
    "    y_pred = np.where(y_pred1 > 0.5, 1, 0)\n",
    "    #print(y_pred1)\n",
    "    # print(y_test)\n",
    "    \n",
    "    #nomalize default is true here\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    test_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    print('Test accuracy with normalize flase: \\n', test_acc)  \n",
    "\n",
    "    total_acc = np.zeros(9)\n",
    "    acc = 0\n",
    "    for i in range(9):\n",
    "        total_acc[i] = accuracy_score(y_test[:, i],y_pred[:, i], normalize=False)\n",
    "        acc += total_acc[i]\n",
    "    \n",
    "    size = np.shape(y_test)[0] * 9\n",
    "    acc /= size\n",
    "    print(\"The accuracy calculate via MLP is: \"+ str(acc))\n",
    " \n",
    "    \n",
    "    filename = 'mlp_model.pkl'\n",
    "    pickle.dump(reg, open(filename, 'wb'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acc1fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.31781663 0.43431111        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best socre is: \n",
      "0.43431111100249664\n",
      "The best params is: \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (150, 100, 50, 10), 'learning_rate': 'constant'}\n",
      "Test accuracy: 0.4766265979774852\n",
      "Test accuracy with normalize flase: \n",
      " 2498\n",
      "The accuracy calculate via MLP is: 0.9007398927261548\n"
     ]
    }
   ],
   "source": [
    "MLP_regressor(x_train2, y_train2, x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da378ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
